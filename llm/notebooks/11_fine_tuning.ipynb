{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Fine-Tuning\n",
    "\n",
    "Adapter le mod√®le √† des t√¢ches sp√©cifiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qu'est-ce que le Fine-Tuning ?\n",
    "\n",
    "### Pr√©-entra√Ænement vs Fine-tuning\n",
    "\n",
    "**Pr√©-entra√Ænement** :\n",
    "- Large corpus (ex: tout Internet)\n",
    "- T√¢che g√©n√©rale : pr√©dire le prochain token\n",
    "- Apprentissage non supervis√©\n",
    "- Co√ªteux en temps et ressources\n",
    "\n",
    "**Fine-tuning** :\n",
    "- Dataset sp√©cifique (ex: dialogues, code, m√©dical)\n",
    "- T√¢che cibl√©e (ex: Q&A, classification, g√©n√©ration)\n",
    "- Apprentissage supervis√©\n",
    "- Rapide et efficace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strat√©gies de Fine-Tuning\n",
    "\n",
    "### 1. Full Fine-Tuning\n",
    "Mettre √† jour tous les poids du mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_fine_tuning(model, task_data, config):\n",
    "    \"\"\"\n",
    "    Fine-tune tous les param√®tres du mod√®le.\n",
    "    \n",
    "    Args:\n",
    "        model: Mod√®le pr√©-entra√Æn√©\n",
    "        task_data: Dataset sp√©cifique √† la t√¢che\n",
    "        config: Configuration (learning rate, epochs, etc.)\n",
    "    \"\"\"\n",
    "    optimizer = AdamOptimizer(learning_rate=config['lr'])\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        for x, y in task_data:\n",
    "            # Forward\n",
    "            logits = model.forward(x)\n",
    "            loss = cross_entropy_loss(logits, y)\n",
    "            \n",
    "            # Backward\n",
    "            grads = model.backward(y)\n",
    "            \n",
    "            # Update ALL parameters\n",
    "            optimizer.update(model.parameters, grads)\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Full Fine-Tuning: Met √† jour tous les poids\")\n",
    "print(\"   Avantages: Meilleure adaptation\")\n",
    "print(\"   Inconv√©nients: Co√ªteux, risque de catastrophic forgetting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Extraction (Frozen Embeddings)\n",
    "Geler les embeddings, entra√Æner seulement les couches sup√©rieures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_fine_tuning(model, task_data, config):\n",
    "    \"\"\"\n",
    "    Fine-tune avec embeddings gel√©s.\n",
    "    \"\"\"\n",
    "    optimizer = AdamOptimizer(learning_rate=config['lr'])\n",
    "    \n",
    "    # Freeze embeddings\n",
    "    frozen_params = ['token_embedding', 'pos_encoding']\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        for x, y in task_data:\n",
    "            logits = model.forward(x)\n",
    "            loss = cross_entropy_loss(logits, y)\n",
    "            grads = model.backward(y)\n",
    "            \n",
    "            # Update only non-frozen parameters\n",
    "            trainable_params = {k: v for k, v in model.parameters.items() \n",
    "                               if k not in frozen_params}\n",
    "            trainable_grads = {k: v for k, v in grads.items() \n",
    "                              if k not in frozen_params}\n",
    "            \n",
    "            optimizer.update(trainable_params, trainable_grads)\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚ùÑÔ∏è Feature Extraction: G√®le les embeddings\")\n",
    "print(\"   Avantages: Plus rapide, moins de param√®tres\")\n",
    "print(\"   Inconv√©nients: Adaptation limit√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Layer-wise Learning Rate\n",
    "Learning rates diff√©rents par couche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerwise_lr_fine_tuning(model, task_data, config):\n",
    "    \"\"\"\n",
    "    Fine-tune avec learning rates diff√©rents par couche.\n",
    "    \n",
    "    Principe: Les couches basses (embeddings) changent peu,\n",
    "              les couches hautes (output) changent plus.\n",
    "    \"\"\"\n",
    "    # Learning rates d√©croissants par couche\n",
    "    layer_lrs = {\n",
    "        'token_embedding': config['lr'] * 0.1,\n",
    "        'pos_encoding': config['lr'] * 0.1,\n",
    "        'blocks': config['lr'] * 0.5,\n",
    "        'output_proj': config['lr'] * 1.0\n",
    "    }\n",
    "    \n",
    "    optimizers = {name: AdamOptimizer(learning_rate=lr) \n",
    "                 for name, lr in layer_lrs.items()}\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        for x, y in task_data:\n",
    "            logits = model.forward(x)\n",
    "            loss = cross_entropy_loss(logits, y)\n",
    "            grads = model.backward(y)\n",
    "            \n",
    "            # Update avec diff√©rents learning rates\n",
    "            for layer_name, optimizer in optimizers.items():\n",
    "                layer_params = {k: v for k, v in model.parameters.items() \n",
    "                               if layer_name in k}\n",
    "                layer_grads = {k: v for k, v in grads.items() \n",
    "                              if layer_name in k}\n",
    "                optimizer.update(layer_params, layer_grads)\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"üìä Layer-wise LR: Learning rates adaptatifs\")\n",
    "print(\"   Couches basses: LR faible (0.1x)\")\n",
    "print(\"   Couches interm√©diaires: LR moyen (0.5x)\")\n",
    "print(\"   Couches hautes: LR fort (1.0x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple: Fine-Tuning pour Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset de Q&A\n",
    "qa_dataset = [\n",
    "    {\"question\": \"What is the capital of France?\", \n",
    "     \"answer\": \"The capital of France is Paris.\"},\n",
    "    {\"question\": \"Who wrote Romeo and Juliet?\", \n",
    "     \"answer\": \"William Shakespeare wrote Romeo and Juliet.\"},\n",
    "    {\"question\": \"What is 2 + 2?\", \n",
    "     \"answer\": \"2 + 2 equals 4.\"},\n",
    "]\n",
    "\n",
    "# Format pour le fine-tuning\n",
    "def prepare_qa_data(qa_dataset):\n",
    "    \"\"\"\n",
    "    Formate les paires Q&A pour l'entra√Ænement.\n",
    "    \n",
    "    Format: \"Q: {question}\\nA: {answer}\"\n",
    "    \"\"\"\n",
    "    formatted_data = []\n",
    "    \n",
    "    for item in qa_dataset:\n",
    "        text = f\"Q: {item['question']}\\nA: {item['answer']}\"\n",
    "        \n",
    "        # Encode\n",
    "        tokens = encode(text)\n",
    "        \n",
    "        # Input = tout sauf dernier token\n",
    "        # Target = tout sauf premier token\n",
    "        x = tokens[:-1]\n",
    "        y = tokens[1:]\n",
    "        \n",
    "        formatted_data.append((x, y))\n",
    "    \n",
    "    return formatted_data\n",
    "\n",
    "# Pr√©parer les donn√©es\n",
    "train_data = prepare_qa_data(qa_dataset)\n",
    "\n",
    "print(f\"Dataset Q&A pr√©par√©: {len(train_data)} exemples\")\n",
    "print(f\"\\nExemple:\")\n",
    "print(f\"  Question: {qa_dataset[0]['question']}\")\n",
    "print(f\"  R√©ponse: {qa_dataset[0]['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©venir le Catastrophic Forgetting\n",
    "\n",
    "### Techniques :\n",
    "\n",
    "1. **Lower Learning Rate** : Utiliser un LR plus faible que le pr√©-entra√Ænement\n",
    "2. **Fewer Epochs** : Ne pas surentra√Æner\n",
    "3. **Regularization** : L2, Dropout\n",
    "4. **Mix General Data** : M√©langer donn√©es g√©n√©rales + sp√©cifiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration pour √©viter le catastrophic forgetting\n",
    "safe_config = {\n",
    "    'lr': 0.0001,  # 10x plus petit que pr√©-entra√Ænement\n",
    "    'epochs': 3,    # Peu d'epochs\n",
    "    'batch_size': 16,\n",
    "    'dropout': 0.1,\n",
    "    'weight_decay': 0.01  # L2 regularization\n",
    "}\n",
    "\n",
    "print(\"üõ°Ô∏è Configuration s√ªre pour le fine-tuning:\")\n",
    "for key, value in safe_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âvaluation du Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_qa_model(model, test_questions):\n",
    "    \"\"\"\n",
    "    √âvalue le mod√®le fine-tun√© sur des questions.\n",
    "    \"\"\"\n",
    "    for question in test_questions:\n",
    "        prompt = f\"Q: {question}\\nA:\"\n",
    "        \n",
    "        # G√©n√©rer la r√©ponse\n",
    "        answer = generate_text(model, prompt, max_length=20, \n",
    "                              strategy='top_p', p=0.9, temperature=0.7)\n",
    "        \n",
    "        print(f\"Q: {question}\")\n",
    "        print(f\"A: {answer}\\n\")\n",
    "\n",
    "# Test questions\n",
    "test_questions = [\n",
    "    \"What is the capital of Italy?\",\n",
    "    \"Who painted the Mona Lisa?\",\n",
    "    \"What is 10 + 5?\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Test du mod√®le fine-tun√©:\")\n",
    "# evaluate_qa_model(finetuned_model, test_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation: Avant vs Apr√®s Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simuler les performances\n",
    "metrics = {\n",
    "    'General Tasks': [0.75, 0.73],  # L√©g√®re baisse acceptable\n",
    "    'Q&A Task': [0.45, 0.92],       # Forte am√©lioration\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "before = [v[0] for v in metrics.values()]\n",
    "after = [v[1] for v in metrics.values()]\n",
    "\n",
    "ax.bar(x - width/2, before, width, label='Avant Fine-Tuning', alpha=0.8)\n",
    "ax.bar(x + width/2, after, width, label='Apr√®s Fine-Tuning', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Impact du Fine-Tuning')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics.keys())\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìà R√©sultats:\")\n",
    "print(\"  ‚Ä¢ T√¢ches g√©n√©rales: L√©g√®re baisse (75% ‚Üí 73%)\")\n",
    "print(\"  ‚Ä¢ T√¢che Q&A: Forte am√©lioration (45% ‚Üí 92%)\")\n",
    "print(\"  ‚úÖ Trade-off acceptable !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
